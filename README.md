# üå± Chat'Bruti - Interface Streamlit

Interface web interactive pour dialoguer avec Chat'Bruti, le philosophe permaculturel absurde, via Ollama.

## üåê Acc√®s en ligne

**Application d√©ploy√©e :** [http://162.38.112.231/](http://162.38.112.231/)

## üìã Description

Chat'Bruti est un chatbot philosophe qui ne r√©pond jamais directement aux questions et m√©lange constamment plusieurs langues (grec, cyrillique, arabe, chinois, etc.) dans ses r√©ponses. Il est obs√©d√© par les timbres et transforme chaque question en r√©flexion absurde.

Ce projet a √©t√© d√©velopp√© dans le cadre de la **Nuit de l'Info 2025** pour le d√©fi **Chat'bruti** propos√© par Viveris.

## üîÑ D√©marche

Dans un premier temps, nous avons tent√© une approche de **fine-tuning** en utilisant un **ADAPTER** dans la directive `FROM` du Modelfile. Cette m√©thode permettait th√©oriquement d'adapter un mod√®le de base avec des param√®tres sp√©cifiques pour obtenir le comportement d√©sir√© de Chat'Bruti.

Cependant, apr√®s plusieurs essais, les r√©sultats obtenus n'√©taient pas satisfaisants : le mod√®le ne respectait pas suffisamment les contraintes de personnalit√© (m√©lange de langues, obsession des timbres, non-r√©ponse directe aux questions, etc.).

Nous avons donc opt√© pour une **d√©marche plus simple et plus efficace** :

- Utilisation directe du mod√®le **mistral-small:22b** dans la directive `FROM`
- Sp√©cification d√©taill√©e de toutes les consignes de personnalit√©, de style et de comportement dans la section `SYSTEM` du Modelfile

Cette approche s'est r√©v√©l√©e beaucoup plus facile, permettant d'obtenir un Chat'Bruti fid√®le √† sa personnalit√© absurde et multilingue, tout en restant simple √† maintenir et √† ajuster.

## üöÄ Installation

### Pr√©requis

1. **Python 3.8+** install√©
2. **Ollama** install√© et lanc√©
3. **Mod√®le Chat'Bruti** cr√©√© dans Ollama

### √âtapes d'installation

1. **Installer les d√©pendances** :

```bash
pip install -r requirements.txt
```

2. **V√©rifier qu'Ollama est lanc√©** :

```bash
# Dans un terminal s√©par√©
ollama serve
```

3. **Pull le mod√®le mistral-small:22b** :

```bash
ollama pull mistral-small:22b
```

4. **Cr√©er le mod√®le** :

```bash
ollama create blablabruti2 -f Modelfile
```

## üéØ Utilisation

### Lancer l'application en local

**Option 1 : Port par d√©faut (8501)**

```bash
streamlit run app.py
```

L'application sera accessible sur `http://localhost:8501`

## üîó Ressources

- [Documentation Streamlit](https://docs.streamlit.io/)
- [Documentation Ollama Python](https://github.com/ollama/ollama-python)
- [Ollama API](https://github.com/ollama/ollama/blob/main/docs/api.md)

## üë• √âquipe

**DISTRACTED/DEFIANT TOUGH NEWTS**

Projet r√©alis√© dans le cadre de la Nuit de l'Info 2025.
