# Guide complet : Entra√Æner un adapter LoRA pour Blablabruti

Ce guide vous permettra de cr√©er un adapter LoRA qui forcera Mistral 7B (ou 22B) √† incarner parfaitement **Blablabruti**, le chatbot philosophe du dimanche passionn√© de timbres.

**Temps estim√© : 2-4 heures selon votre mat√©riel**

---

## üìã √âtape 1 : Pr√©parer l'environnement

### 1.1 V√©rifier les pr√©requis

**Mat√©riel n√©cessaire :**

- GPU NVIDIA avec au moins **8 GB VRAM** (Mistral 7B) ou **16 GB+** (Mistral 22B)
- **50 GB** d'espace disque libre
- Linux, macOS, ou Windows avec WSL2

**V√©rifier votre GPU :**

```bash
nvidia-smi
```

### 1.2 Installer les d√©pendances

```bash
# Cr√©er un environnement virtuel
python3 -m venv blablabruti-env
source blablabruti-env/bin/activate  # Sur Windows: blablabruti-env\Scripts\activate

# Installer unsloth (le plus simple pour d√©buter)
pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"
pip install --no-deps trl peft accelerate bitsandbytes
```

---

## üìö √âtape 2 : Cr√©er le dataset d'entra√Ænement

### 2.1 Le fichier `chatbruti_dataset.json`

Le fichier `chatbruti_dataset.json` contient **30 exemples** de conversations avec Blablabruti. Chaque exemple montre :

- Le m√©lange de langues (grec, cyrillique, h√©breu, chinois, etc.)
- La passion pour les timbres (m√™me quand la question n'est pas li√©e)
- Le style absurde et philosophique

**Format :**

```json
[
  {
    "conversations": [
      {"from": "human", "value": "Question"},
      {"from": "gpt", "value": "R√©ponse de Blablabruti avec m√©lange de langues et r√©f√©rence aux timbres"}
    ]
  }
]
```

**‚ö†Ô∏è IMPORTANT :** Plus vous avez d'exemples (100-500+), meilleur sera votre adapter. Les 30 exemples fournis sont un d√©but. Id√©alement, cr√©ez 100-200 exemples en variant les questions tout en gardant le style Blablabruti.

**Conseils pour cr√©er plus d'exemples :**

- Variez les types de questions (techniques, philosophiques, pratiques, absurdes)
- Toujours d√©tourner vers les timbres
- Toujours m√©langer plusieurs langues
- Garder le ton absurde et s√ªr de soi

---

## üéì √âtape 3 : Script de fine-tuning

### 3.1 Le fichier `train_blablabruti.py`

Le script est d√©j√† cr√©√© et configur√©. Il utilise :

- **Mistral 7B** par d√©faut (changeable pour 22B)
- **LoRA** avec rang 16
- **Quantization 4-bit** pour √©conomiser la VRAM
- **Format Mistral** (`<|im_start|>user/assistant<|im_end|>`)

### 3.2 Lancer l'entra√Ænement

```bash
python train_blablabruti.py
```

**Temps estim√© :** 30 minutes √† 2 heures selon votre GPU et la quantit√© de donn√©es.

**Param√®tres ajustables dans le script :**

- `r=16` : Rang LoRA (augmentez √† 32 pour plus de capacit√©, mais plus de VRAM)
- `max_steps=500` : Nombre d'√©tapes (augmentez √† 1000-2000 pour plus de donn√©es)
- `per_device_train_batch_size=2` : R√©duisez √† 1 si vous manquez de VRAM
- `gradient_accumulation_steps=4` : Augmentez √† 8 si batch_size=1

**Pour utiliser Mistral 22B :**
Changez dans le script :

```python
model_name = "unsloth/mistral-22b-v0.3-bnb-4bit"
```

---

## üß™ √âtape 4 : Tester le mod√®le

### 4.1 Cr√©er un script de test

Cr√©ez `test_model.py` :

```python
from unsloth import FastLanguageModel
from transformers import TextStreamer

# Charger le mod√®le entra√Æn√©
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="./blablabruti-lora-final",
    max_seq_length=2048,
    dtype=None,
    load_in_4bit=True,
)

FastLanguageModel.for_inference(model)

# Tester
prompt = "<|im_start|>user\nBonjour<|im_end|>\n<|im_start|>assistant\n"
inputs = tokenizer([prompt], return_tensors="pt").to("cuda")

text_streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)
_ = model.generate(**inputs, streamer=text_streamer, max_new_tokens=256, temperature=0.9)
```

Lancez :

```bash
python test_model.py
```

---

## üîÑ √âtape 5 : Utiliser avec Ollama (Option 1)

### 5.1 Exporter en format Ollama

Ollama peut utiliser les adapters LoRA directement. Cr√©ez un Modelfile :

```dockerfile
FROM mistral:7b

ADAPTER ./blablabruti-lora-final

PARAMETER temperature 0.9
PARAMETER num_ctx 8192
```

Puis :

```bash
ollama create blablabruti -f Modelfile
ollama run blablabruti
```

---

## üîÑ √âtape 6 : Convertir en GGUF (Option 2)

### 6.1 Installer llama.cpp

```bash
git clone https://github.com/ggerganov/llama.cpp
cd llama.cpp
make
```

### 6.2 Fusionner le LoRA avec le mod√®le de base

```bash
# D'abord, t√©l√©charger le mod√®le Mistral 7B complet
# Puis fusionner avec le LoRA
python llama.cpp/convert_lora_to_gguf.py \
  --base-model-path /path/to/mistral-7b \
  --lora-path ./blablabruti-lora-final \
  --outfile blablabruti.gguf
```

---

## üéØ √âtape 7 : Optimisations et conseils

### 7.1 Am√©liorer les performances

**Si le mod√®le ne suit pas assez le style :**

- Augmentez `r=32` (rang LoRA)
- Augmentez `max_steps=1000-2000`
- Ajoutez plus d'exemples au dataset (100-200+)

**Si vous manquez de VRAM :**

- R√©duisez `per_device_train_batch_size=1`
- Augmentez `gradient_accumulation_steps=8`
- Utilisez Mistral 7B au lieu de 22B

### 7.2 Cr√©er plus d'exemples

Utilisez votre Modelfile actuel avec Ollama pour g√©n√©rer des exemples :

```bash
ollama run blablabruti
```

Posez des questions vari√©es et sauvegardez les r√©ponses dans le format JSON du dataset.

---

## üìä R√©sultats attendus

Apr√®s l'entra√Ænement, Blablabruti devrait :

- ‚úÖ Toujours d√©tourner vers les timbres
- ‚úÖ M√©langer plusieurs langues dans chaque r√©ponse
- ‚úÖ Avoir un ton absurde et s√ªr de soi
- ‚úÖ Ne jamais r√©pondre directement aux questions
- ‚úÖ √ätre inutile mais attachant

---

## üêõ D√©pannage

**Erreur "Out of memory" :**

- R√©duisez `per_device_train_batch_size=1`
- Utilisez Mistral 7B au lieu de 22B
- Fermez les autres applications utilisant le GPU

**Le mod√®le ne suit pas le style :**

- Augmentez le nombre d'exemples (100+)
- Augmentez `max_steps=1000-2000`
- V√©rifiez que vos exemples sont coh√©rents avec le style

**Erreur d'import :**

- V√©rifiez que vous √™tes dans l'environnement virtuel
- R√©installez les d√©pendances : `pip install --upgrade unsloth`

---

## üéâ C'est parti

Vous avez maintenant tout ce qu'il faut pour entra√Æner Blablabruti. Bon entra√Ænement ! üöÄ
